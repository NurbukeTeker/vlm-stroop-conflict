
| Image File | Word | Ink Color | Congruency |
|-------------|-------|-----------|-------------|
| `red_as_red.png` | RED | red | âœ… Congruent |
| `blue_as_green.png` | BLUE | green | âŒ Incongruent |

Each color folder contains 10 PNG images, one for every possible color pairing.

---

## ğŸ§© Experimental Goal

The Stroop paradigm tests **modality dominance** in Vision-Language Models â€” whether the model â€œreadsâ€ or â€œseesâ€ more strongly.

| Prompt Type | Example Prompt | Focus |
|--------------|----------------|--------|
| **Word-Oriented** | â€œThe text says BLUE.â€ | Semantic meaning (word identity) |
| **Ink-Oriented** | â€œThe text is written in blue color.â€ | Visual appearance (font color) |

By comparing model accuracy under **congruent** (word = color)  
and **incongruent** (word â‰  color) stimuli,  
we reveal whether CLIP favors textual or visual information when these conflict.

---

## âš™ï¸ Running the Analysis

Make sure you have the environment set up (Python â‰¥ 3.10, CUDA optional):

```bash
conda activate vlm-stroop-conflict
pip install torch torchvision transformers pillow pandas tqdm scikit-learn
