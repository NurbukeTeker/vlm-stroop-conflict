# ğŸ¨ CLIP RDM Analysis â€” Stroop-Style Visual Conflicts

This directory contains **Representational Dissimilarity Matrix (RDM)** analyses for the Stroop-style experiments performed with **CLIP (ViT-B/32)**.  
The goal is to compare how CLIPâ€™s embedding space represents **color**, **shape (word form)**, and their **combination** when word and ink cues align.

---

## ğŸ§© Overview

We compute three types of RDMs and two difference (Î”) maps:

| Dataset | Description | Purpose |
|----------|--------------|----------|
| **Grayscale** | Word-only stimuli (no color) | Measures *shape-based* similarity |
| **Color Patches** | Solid color backgrounds (no words) | Measures *color-based* similarity |
| **Stroop (Congruent)** | Words rendered in matching ink colors (e.g., â€œREDâ€ in red) | Combines color and word cues |
| **Î”Shape (Î”Word)** | Stroop âˆ’ Color | Added dissimilarity due to **word/shape** information |
| **Î”Color (Î”Ink)** | Stroop âˆ’ Grayscale | Added dissimilarity due to **color** information |

---

## âš™ï¸ How to Reproduce

1. Make sure the following directories exist and contain 10 images each:
stroop_images/
embedding_level_analysis/clip_rdm_analysis/grayscale_images/
embedding_level_analysis/clip_rdm_analysis/color_patches_single/


2. Run the RDM generator:

```bash
python embedding_level_analysis/clip_rdm_analysis/delta_RDM.py

All .npy matrices and figures will be saved under:

embedding_level_analysis/clip_rdm_analysis/rdm_heatmaps/
â”œâ”€â”€ RDM_stroop.npy
â”œâ”€â”€ RDM_grayscale.npy
â”œâ”€â”€ RDM_color.npy
â”œâ”€â”€ Î”Word.npy
â”œâ”€â”€ Î”Ink.npy
â””â”€â”€ figures/

Color Scheme

All figures use a pure blueâ€“whiteâ€“red palette:

Color	Meaning
ğŸ”µ Blue	Low dissimilarity (high similarity)
âšª White	Mid-level dissimilarity
ğŸ”´ Red	High dissimilarity (low similarity)

This scale visually emphasizes representational distance between color and shape concepts in CLIPâ€™s embedding space.

ğŸ“Š Results
1ï¸âƒ£ Grayscale vs. Stroop (Shape vs. Color+Shape)

Shows how adding color information changes representational distances.

<p align="center"> <img src="figures/RDM_gray_vs_stroop_blue_red.png" width="85%"> </p>

Observation: The Stroop RDM (right) shows increased dissimilarity between classes that differ by both color and word, indicating that combined visual and textual cues expand representational separation.

2ï¸âƒ£ Color vs. Stroop (Color vs. Color+Shape)

Shows how adding word form changes representational geometry.

<p align="center"> <img src="figures/RDM_color_vs_stroop_blue_red.png" width="85%"> </p>

Observation: CLIP embeddings encode shape (word form) as a more distinct dimension than pure color. Adding word information (right) increases pairwise dissimilarities, showing that text structure dominates representation.

3ï¸âƒ£ Î”RDMs (Î”Shape and Î”Color)

Difference maps quantifying the added dissimilarity due to shape or color cues.

<p align="center"> <img src="figures/Delta_RDMs_blue_red.png" width="85%"> </p>

Interpretation:

Î”Shape (left): Adding word form contributes stronger dissimilarity shifts (more red), confirming CLIPâ€™s sensitivity to textual shapes.

Î”Color (right): Adding color yields weaker and more diffuse effects, consistent with a weaker color representation in the embedding space.

ğŸ§© Summary
Contrast	Strong Effect	Weak Effect	Interpretation
Stroop âˆ’ Color	âœ… Shape	âŒ Color	Word form dominates
Stroop âˆ’ Grayscale	âšª Moderate	âšª Diffuse	Color adds minor separation

Overall, CLIP â€œreadsâ€ more than it â€œseesâ€ â€” word/shape cues are represented more saliently than color cues, leading to a Stroop-style bias at the embedding level.